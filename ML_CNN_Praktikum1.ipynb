{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnyAvQjvI8X7TPfpqdLCe2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firstiaaa/Pemb_Mesin/blob/main/ML_CNN_Praktikum1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAMA  : FIRSTIA AULIA WIDA AZIZAH\n",
        "\n",
        "KELAS : TI-3H / 11"
      ],
      "metadata": {
        "id": "1-5cR3lwS9Ba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PRAKTIKUM 1 - KLASIFIKASI KUCING DAN ANJING"
      ],
      "metadata": {
        "id": "OxgFFbCgavJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 1 - Import Library"
      ],
      "metadata": {
        "id": "9YZSYIPyTPCi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqrFyKYmRrg3",
        "outputId": "13b2c5ef-c57e-4682-c7b7-12c8966a3512"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# access and manipulate files stored in your Google Drive directly from the Colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dHVkLipbL2H",
        "outputId": "2c1f861b-f9de-4d3d-aa60-01e2ec269ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "5UjcQXzXeRgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y6M_mxCueVL8",
        "outputId": "2ceddb7b-3ff1-4817-eced-2d18db72ad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting keras>=3.5.0 (from tensorflow)\n",
            "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.6.0 tensorboard-2.18.0 tensorflow-2.18.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorflow"
                ]
              },
              "id": "fab439c1d6c44f4584a3a1cb46ac0f65"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "MIN8nbffe1Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langkah 2 - Pra Pengolahan Data"
      ],
      "metadata": {
        "id": "KYLBqynyTgkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 2.1 Pra Pengolahan Data Training\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "# utilizes the flow_from_directory() method of the ImageDataGenerator object train_datagen to generate batches of training data\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/P_Mesin/dataset/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRhd806gTk_x",
        "outputId": "8496d43e-659f-4840-bdce-6b98b461290a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8010 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2 Pra Pengolahan Data Testing\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/P_Mesin/dataset/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rix4jUpXtk6u",
        "outputId": "2f0bcfe9-0bf0-4bfc-fb0b-3e03478bc125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LANGKAH 3 - PEMBUATAN MODEL CNN"
      ],
      "metadata": {
        "id": "TCUwghyfGB3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3.1 - Inisial Model CNN\n",
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "z7EhAU6iF_3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3.2 - Pembuatan Layer Konvolusi 1\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61fa2ls-HV1Y",
        "outputId": "5bd68d2c-2153-49f6-bfcb-56a10f0171df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3.3 - Pembuatan Layer Pooling 1\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "bw5WypsQHdZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3.4 - Pembuatan Layer Konvolusi 2 dan Pooling 2\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "IcNGTQG7HmEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3.5 - Flattening\n",
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "aP65GLqOHuje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Langkah 3.6 - Fully Connected Layer 1 (Input)\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "mXbyv3SmH3xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Langkah 3.7 - Fully Connected Layer 2 (Output)\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "JwaEn170H7Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Langkah 3.8 - Compile Model CNN\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "YneaDz_eIBO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LANGKAH 4 - FIT CNN"
      ],
      "metadata": {
        "id": "tyWj_mZFIIZq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k91f8jwgIPlh",
        "outputId": "aad5a99e-5785-41db-b3f3-9afa09f2cf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 368ms/step - accuracy: 0.9106 - loss: 0.2128 - val_accuracy: 0.8080 - val_loss: 0.5477\n",
            "Epoch 2/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 343ms/step - accuracy: 0.9197 - loss: 0.1996 - val_accuracy: 0.8050 - val_loss: 0.5669\n",
            "Epoch 3/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 345ms/step - accuracy: 0.9231 - loss: 0.1851 - val_accuracy: 0.8065 - val_loss: 0.6056\n",
            "Epoch 4/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 377ms/step - accuracy: 0.9278 - loss: 0.1802 - val_accuracy: 0.7990 - val_loss: 0.6497\n",
            "Epoch 5/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 347ms/step - accuracy: 0.9310 - loss: 0.1696 - val_accuracy: 0.7900 - val_loss: 0.6315\n",
            "Epoch 6/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 338ms/step - accuracy: 0.9396 - loss: 0.1585 - val_accuracy: 0.8025 - val_loss: 0.6390\n",
            "Epoch 7/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 343ms/step - accuracy: 0.9396 - loss: 0.1519 - val_accuracy: 0.7880 - val_loss: 0.7602\n",
            "Epoch 8/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 334ms/step - accuracy: 0.9421 - loss: 0.1487 - val_accuracy: 0.8035 - val_loss: 0.6576\n",
            "Epoch 9/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 337ms/step - accuracy: 0.9418 - loss: 0.1406 - val_accuracy: 0.7955 - val_loss: 0.7092\n",
            "Epoch 10/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 337ms/step - accuracy: 0.9382 - loss: 0.1515 - val_accuracy: 0.7860 - val_loss: 0.6845\n",
            "Epoch 11/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 338ms/step - accuracy: 0.9482 - loss: 0.1368 - val_accuracy: 0.8060 - val_loss: 0.6805\n",
            "Epoch 12/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 330ms/step - accuracy: 0.9524 - loss: 0.1260 - val_accuracy: 0.8000 - val_loss: 0.6806\n",
            "Epoch 13/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 346ms/step - accuracy: 0.9565 - loss: 0.1145 - val_accuracy: 0.8050 - val_loss: 0.7084\n",
            "Epoch 14/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 338ms/step - accuracy: 0.9465 - loss: 0.1399 - val_accuracy: 0.8000 - val_loss: 0.6857\n",
            "Epoch 15/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 343ms/step - accuracy: 0.9591 - loss: 0.1034 - val_accuracy: 0.8035 - val_loss: 0.7309\n",
            "Epoch 16/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 337ms/step - accuracy: 0.9632 - loss: 0.1022 - val_accuracy: 0.8010 - val_loss: 0.7548\n",
            "Epoch 17/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 333ms/step - accuracy: 0.9620 - loss: 0.1020 - val_accuracy: 0.8100 - val_loss: 0.7307\n",
            "Epoch 18/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 347ms/step - accuracy: 0.9636 - loss: 0.0963 - val_accuracy: 0.7960 - val_loss: 0.7730\n",
            "Epoch 19/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 344ms/step - accuracy: 0.9623 - loss: 0.0979 - val_accuracy: 0.7965 - val_loss: 0.7100\n",
            "Epoch 20/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 377ms/step - accuracy: 0.9659 - loss: 0.1005 - val_accuracy: 0.8105 - val_loss: 0.7934\n",
            "Epoch 21/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 338ms/step - accuracy: 0.9677 - loss: 0.0850 - val_accuracy: 0.7920 - val_loss: 0.8920\n",
            "Epoch 22/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 384ms/step - accuracy: 0.9657 - loss: 0.0933 - val_accuracy: 0.7870 - val_loss: 0.9261\n",
            "Epoch 23/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 335ms/step - accuracy: 0.9720 - loss: 0.0889 - val_accuracy: 0.7915 - val_loss: 0.9115\n",
            "Epoch 24/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 344ms/step - accuracy: 0.9735 - loss: 0.0773 - val_accuracy: 0.7995 - val_loss: 0.8199\n",
            "Epoch 25/25\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 336ms/step - accuracy: 0.9685 - loss: 0.0807 - val_accuracy: 0.7955 - val_loss: 0.9577\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fa68d877dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LANGKAH 5 - PREDIKSI DENGAN 1 CITRA"
      ],
      "metadata": {
        "id": "BnbvHYkYIRx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# load image\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/drive/MyDrive/P_Mesin/dataset/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpWvHEILIOqX",
        "outputId": "989436a9-6ce1-4be6-b953-4bbf6e5b0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
          ]
        }
      ]
    }
  ]
}