{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firstiaaa/Pemb_Mesin/blob/main/UTS_ML_Kelompok_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTS Machine Learning Kelompok 3 TI - 3H\n",
        "  - Brilyan Satria Wahyuda | 2241720019\n",
        "  - Firstia Aulia Wida Azizah | 2241720135\n",
        "  - Fransiscus Farrel Edric Wijanarko | 2241720032\n",
        "  - M. Tryo Bagus Anugerah Putra | 2241720053  "
      ],
      "metadata": {
        "id": "VtpyzMw-I6kW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38FnGGAyJMfp"
      },
      "source": [
        "# Intro\n",
        "\n",
        "Pada kuis ini, Anda diminta untuk melakukan klasifikasi citra wajah dengan menggunakan dataset [CISIA Webface](https://www.kaggle.com/datasets/ntl0601/casia-webface). Perhatian! Dataset ini cukup besar (2.8Gb) dari 500.000 gambar dan 10.575 subjek (label)\n",
        "Spesifikasi pengerjaan UTS yang harus dipehuni adalah,\n",
        "\n",
        "1. Pelajari tentang CISIA Webface!\n",
        "2. Dikarenakan data gambar dari CISIA masih dalam 1 direktori besar, Anda perlu melakukan proses split antara data latih dan data uji. Anda dapat melakukan ini secara manual (langsung dari direktori) atau secara logikal dengan listing direktori. (10 poin)\n",
        "2. Lakukan proses pra pengolahan data. Anda wajib dapat menjelaskan proses pra pengolahan data yang dilakukan. (20 poin)\n",
        "3. Lakukan proses ekstraksi fitur. Fitur yang digunakan bebas. Anda wajib dapat menjelasakan fitur yang digunakan (30 poin)\n",
        "4. Buat model NN dengan arsitektur yang kelompok Anda rancang sendiri. Model arsitektur bebas (jumlah layer, jumlah node, fungsi aktiviasi). (30 poin)\n",
        "6. Evaluasi performa model NN kelompok Anda dengan metrik akurasi, *precision*, *recall*, dan *F1-Score*. Jelaskan maksud dari metric-metric tersebut!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T70gmJRXJMfq"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Berikut merupakan boilerplate code yang dapat Anda gunakan sebagai acuan dasar pengerjaan kuis.\n",
        "Anda diperkenankan untuk **menambah** ataupun **mengurangi** bagian boilerplate yang disediakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyd97n8vJMfq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc1AAZ5aJMfq"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h2c7m2qJMfq"
      },
      "outputs": [],
      "source": [
        "# Load required library\n",
        "# Import Required Library\n",
        "import kagglehub\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from collections import Counter\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from skimage.color import rgb2gray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4mrPEVsJMfr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knXcOkRDJMfr",
        "outputId": "318a8fc8-37ca-4c8a-b7a9-b9793b932ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset files moved to: /dataset/casia-webface/\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "    Bagian ini dapat Anda gunakan untuk melakukan proses loading data\n",
        "    dan juga proses split antara data latih dan data uji berdasarkan direktori gambar\n",
        "'''\n",
        "\n",
        "# Unduh dataset CASIA-Webface ke folder tujuan\n",
        "path = kagglehub.dataset_download(\"ntl0601/casia-webface\")\n",
        "destination_path = \"/dataset/casia-webface/\"\n",
        "\n",
        "# Cek apakah direktori tujuan ada, jika tidak buat\n",
        "if not os.path.exists(destination_path):\n",
        "    os.makedirs(destination_path)\n",
        "\n",
        "# Pindahkan semua file dari folder download ke folder tujuan\n",
        "if path and os.path.exists(path):\n",
        "    for filename in os.listdir(path):\n",
        "        shutil.move(os.path.join(path, filename), os.path.join(destination_path, filename))\n",
        "    print(\"Dataset files moved to:\", destination_path)\n",
        "else:\n",
        "    print(\"Failed to download dataset or dataset path does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk melakukan sampling data\n",
        "def sample_images(data_dir, min_images_per_person=100, max_images_per_person=100, max_person=50):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = []\n",
        "    person_count = 0  # Menghitung jumlah orang yang diproses\n",
        "\n",
        "    # Iterasi semua folder dan file dalam dataset\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        if len(files) >= min_images_per_person and person_count < max_person:\n",
        "            class_name = os.path.basename(root)\n",
        "\n",
        "            # Pastikan hanya menambahkan kelas baru jika belum ada\n",
        "            if class_name not in class_names:\n",
        "                class_names.append(class_name)\n",
        "                person_count += 1\n",
        "\n",
        "            label = class_names.index(class_name)\n",
        "            print(f\"Loading images from {root}...\")  # Debugging log\n",
        "\n",
        "            # Batas jumlah gambar yang diproses per orang\n",
        "            image_count = 0\n",
        "            for img_name in files:\n",
        "                if image_count >= max_images_per_person:\n",
        "                    break  # Hentikan jika mencapai batas gambar per orang\n",
        "\n",
        "                img_path = os.path.join(root, img_name)\n",
        "\n",
        "                if os.path.isfile(img_path):\n",
        "                    try:\n",
        "                        with Image.open(img_path) as img:\n",
        "                            img = img.convert('RGB').resize((64, 64))\n",
        "                            img = np.array(img) / 255.0\n",
        "\n",
        "                            if img.shape == (64, 64, 3):\n",
        "                                images.append(img)\n",
        "                                labels.append(label)\n",
        "                                image_count += 1  # Tambah jumlah gambar yang valid\n",
        "                            else:\n",
        "                                print(f\"Skipping {img_name}: Invalid shape {img.shape}\")\n",
        "                    except (UnidentifiedImageError, OSError) as e:\n",
        "                        print(f\"Skipping {img_name}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels), class_names\n",
        "\n",
        "# Set Path dan Sampling\n",
        "DATASET_PATH = '/dataset/casia-webface/casia-webface'\n",
        "\n",
        "# Ambil sampel data untuk 50 subjek dengan masing-masing 100 gambar\n",
        "images, labels, class_names = sample_images(DATASET_PATH)\n",
        "\n",
        "print(\"labels:\", labels)\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, stratify=labels)\n",
        "print(test_labels.shape)"
      ],
      "metadata": {
        "id": "KeRw7hZnzGI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23242009-c7aa-4588-c780-ce05d6bf437f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from /dataset/casia-webface/casia-webface/009039...\n",
            "Loading images from /dataset/casia-webface/casia-webface/009544...\n",
            "Loading images from /dataset/casia-webface/casia-webface/008339...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000953...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000105...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002966...\n",
            "Loading images from /dataset/casia-webface/casia-webface/005795...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004088...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000955...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000136...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001002...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001313...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000157...\n",
            "Loading images from /dataset/casia-webface/casia-webface/008700...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004603...\n",
            "Loading images from /dataset/casia-webface/casia-webface/009572...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000697...\n",
            "Loading images from /dataset/casia-webface/casia-webface/006978...\n",
            "Loading images from /dataset/casia-webface/casia-webface/005034...\n",
            "Loading images from /dataset/casia-webface/casia-webface/009771...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000250...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002661...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000844...\n",
            "Loading images from /dataset/casia-webface/casia-webface/008087...\n",
            "Loading images from /dataset/casia-webface/casia-webface/003761...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004890...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004150...\n",
            "Loading images from /dataset/casia-webface/casia-webface/008654...\n",
            "Loading images from /dataset/casia-webface/casia-webface/003153...\n",
            "Loading images from /dataset/casia-webface/casia-webface/003774...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004537...\n",
            "Loading images from /dataset/casia-webface/casia-webface/004818...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002004...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000978...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002218...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000266...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001115...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001629...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000258...\n",
            "Loading images from /dataset/casia-webface/casia-webface/006811...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002486...\n",
            "Loading images from /dataset/casia-webface/casia-webface/005713...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001087...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002554...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000084...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000430...\n",
            "Loading images from /dataset/casia-webface/casia-webface/007144...\n",
            "Loading images from /dataset/casia-webface/casia-webface/001056...\n",
            "Loading images from /dataset/casia-webface/casia-webface/002333...\n",
            "Loading images from /dataset/casia-webface/casia-webface/000138...\n",
            "labels: [ 0  0  0 ... 49 49 49]\n",
            "(1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oweqrAjvJMfr"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpXeX5l0JMfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9a083294-8467-4988-bdaf-c5c816a05669"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Pada bagian ini Anda diperbolehkan untuk melakukan proses pra pengolahan data (preprocessing) sesuai dengan kebutuhan. Pra pengolahan data dapat berupa,\\n\\n    1. Standardisasi nilai fitur ataupun label\\n    2. Penyesuaian ukuran gambar\\n    3. Perubahan colorspace gambar\\n    4. dsb\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "'''\n",
        "    Pada bagian ini Anda diperbolehkan untuk melakukan proses pra pengolahan data (preprocessing) sesuai dengan kebutuhan. Pra pengolahan data dapat berupa,\n",
        "\n",
        "    1. Standardisasi nilai fitur ataupun label\n",
        "    2. Penyesuaian ukuran gambar\n",
        "    3. Perubahan colorspace gambar\n",
        "    4. dsb\n",
        "'''\n",
        "\n",
        "# Preprocessing kita terdapat pada saat load data, yakni resize ukurang gambar menjadi 64X64"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Model ANN tanpa fitur"
      ],
      "metadata": {
        "id": "IM-8lt9drtCV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcLsS56BJMfr"
      },
      "source": [
        "# Features Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em0BVgkdJMfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e0e2bec-5240-4572-9fe2-c08d61b9a303"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Anda dapat melakukan proses ekstrasi fitur apapun sesuai dengan yang apa yang Anda inginkan\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "'''\n",
        "    Anda dapat melakukan proses ekstrasi fitur apapun sesuai dengan yang apa yang Anda inginkan\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FetA_Y0zJMfs"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1FNRicIJMfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a9b9c78e-1492-4c46-df4d-12ad86b16e39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Pada bagian ini lakukan proses pembuatan model NN,\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "'''\n",
        "    Pada bagian ini lakukan proses pembuatan model NN,\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisikan path tempat menyimpan model\n",
        "checkpoint_path = \"model_checkpoint_best.keras\"\n",
        "\n",
        "# Buat callback ModelCheckpoint\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,      # Path untuk menyimpan model\n",
        "    monitor='val_accuracy',        # Metrik yang dipantau, misalnya 'val_accuracy' atau 'val_loss'\n",
        "    save_best_only=True,           # Simpan hanya jika model lebih baik dari sebelumnya\n",
        "    save_weights_only=False,       # Simpan model secara lengkap (termasuk arsitektur dan bobot)\n",
        "    mode='max',                    # Mode 'max' karena kita ingin akurasi tertinggi\n",
        "    verbose=1                      # Aktifkan untuk melihat pesan ketika model disimpan\n",
        ")\n",
        "\n",
        "LABELS_LIMIT = len(np.unique(train_labels))\n",
        "\n",
        "# Arsitektur ANN\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(64, 64, 3)))  # Ubah ukuran gambar ke (64, 64) sesuai dengan memori Colab\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(LABELS_LIMIT, activation='softmax'))\n",
        "\n",
        "\n",
        "# Kompilasi Model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d85oQ0F73LuG",
        "outputId": "37bde2fb-e482-457e-ba81-8c17bd083e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Model\n",
        "history = model.fit(train_images, train_labels, epochs=100, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzftSvpF3-jt",
        "outputId": "fa28a5ac-a6b2-4d43-e19a-2024b26230fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.0250 - loss: 4.0986 - val_accuracy: 0.0450 - val_loss: 3.8547\n",
            "Epoch 2/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0471 - loss: 3.8433 - val_accuracy: 0.0440 - val_loss: 3.7503\n",
            "Epoch 3/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.0505 - loss: 3.7529 - val_accuracy: 0.0510 - val_loss: 3.6520\n",
            "Epoch 4/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.0762 - loss: 3.6070 - val_accuracy: 0.0820 - val_loss: 3.5098\n",
            "Epoch 5/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.1012 - loss: 3.4642 - val_accuracy: 0.0930 - val_loss: 3.3741\n",
            "Epoch 6/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.1161 - loss: 3.3127 - val_accuracy: 0.1600 - val_loss: 3.1530\n",
            "Epoch 7/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1703 - loss: 3.1072 - val_accuracy: 0.1490 - val_loss: 3.1109\n",
            "Epoch 8/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.2039 - loss: 2.9662 - val_accuracy: 0.1930 - val_loss: 2.9157\n",
            "Epoch 9/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2296 - loss: 2.7989 - val_accuracy: 0.2240 - val_loss: 2.8161\n",
            "Epoch 10/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2739 - loss: 2.6201 - val_accuracy: 0.2340 - val_loss: 2.7717\n",
            "Epoch 11/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2766 - loss: 2.5827 - val_accuracy: 0.2520 - val_loss: 2.7462\n",
            "Epoch 12/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2802 - loss: 2.5473 - val_accuracy: 0.2590 - val_loss: 2.6917\n",
            "Epoch 13/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2863 - loss: 2.5294 - val_accuracy: 0.2550 - val_loss: 2.7806\n",
            "Epoch 14/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.3204 - loss: 2.4297 - val_accuracy: 0.3090 - val_loss: 2.5561\n",
            "Epoch 15/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.3396 - loss: 2.3210 - val_accuracy: 0.3200 - val_loss: 2.5019\n",
            "Epoch 16/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3633 - loss: 2.3504 - val_accuracy: 0.2610 - val_loss: 2.7794\n",
            "Epoch 17/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3406 - loss: 2.3676 - val_accuracy: 0.2610 - val_loss: 2.6795\n",
            "Epoch 18/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3794 - loss: 2.1771 - val_accuracy: 0.3360 - val_loss: 2.5171\n",
            "Epoch 19/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.3784 - loss: 2.2036 - val_accuracy: 0.3520 - val_loss: 2.4637\n",
            "Epoch 20/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4228 - loss: 2.0622 - val_accuracy: 0.3450 - val_loss: 2.4592\n",
            "Epoch 21/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4334 - loss: 2.0190 - val_accuracy: 0.3530 - val_loss: 2.4452\n",
            "Epoch 22/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4235 - loss: 2.0606 - val_accuracy: 0.3440 - val_loss: 2.4666\n",
            "Epoch 23/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4312 - loss: 2.0165 - val_accuracy: 0.3090 - val_loss: 2.6161\n",
            "Epoch 24/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4334 - loss: 2.0333 - val_accuracy: 0.3390 - val_loss: 2.4347\n",
            "Epoch 25/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4319 - loss: 1.9975 - val_accuracy: 0.3530 - val_loss: 2.4639\n",
            "Epoch 26/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4509 - loss: 1.9504 - val_accuracy: 0.3730 - val_loss: 2.3568\n",
            "Epoch 27/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4743 - loss: 1.8939 - val_accuracy: 0.3500 - val_loss: 2.4368\n",
            "Epoch 28/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4483 - loss: 1.9283 - val_accuracy: 0.3890 - val_loss: 2.3539\n",
            "Epoch 29/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.4845 - loss: 1.8150 - val_accuracy: 0.3640 - val_loss: 2.4274\n",
            "Epoch 30/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4665 - loss: 1.8505 - val_accuracy: 0.4140 - val_loss: 2.3152\n",
            "Epoch 31/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4860 - loss: 1.7686 - val_accuracy: 0.3780 - val_loss: 2.4819\n",
            "Epoch 32/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4945 - loss: 1.7482 - val_accuracy: 0.3920 - val_loss: 2.3631\n",
            "Epoch 33/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5075 - loss: 1.7381 - val_accuracy: 0.3960 - val_loss: 2.3136\n",
            "Epoch 34/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5086 - loss: 1.7097 - val_accuracy: 0.3860 - val_loss: 2.3005\n",
            "Epoch 35/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5127 - loss: 1.6877 - val_accuracy: 0.3800 - val_loss: 2.3809\n",
            "Epoch 36/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5214 - loss: 1.6635 - val_accuracy: 0.3630 - val_loss: 2.4241\n",
            "Epoch 37/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5142 - loss: 1.6861 - val_accuracy: 0.4000 - val_loss: 2.3375\n",
            "Epoch 38/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5415 - loss: 1.6306 - val_accuracy: 0.4070 - val_loss: 2.3273\n",
            "Epoch 39/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5441 - loss: 1.6120 - val_accuracy: 0.3810 - val_loss: 2.3691\n",
            "Epoch 40/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.5426 - loss: 1.6152 - val_accuracy: 0.4410 - val_loss: 2.2282\n",
            "Epoch 41/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5474 - loss: 1.5672 - val_accuracy: 0.3760 - val_loss: 2.3409\n",
            "Epoch 42/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5661 - loss: 1.5473 - val_accuracy: 0.4080 - val_loss: 2.3256\n",
            "Epoch 43/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5556 - loss: 1.5551 - val_accuracy: 0.4300 - val_loss: 2.2632\n",
            "Epoch 44/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5544 - loss: 1.5701 - val_accuracy: 0.4460 - val_loss: 2.2392\n",
            "Epoch 45/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5701 - loss: 1.5092 - val_accuracy: 0.4170 - val_loss: 2.2860\n",
            "Epoch 46/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6066 - loss: 1.4136 - val_accuracy: 0.4370 - val_loss: 2.2127\n",
            "Epoch 47/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5850 - loss: 1.4287 - val_accuracy: 0.4090 - val_loss: 2.2935\n",
            "Epoch 48/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5663 - loss: 1.5048 - val_accuracy: 0.4290 - val_loss: 2.2882\n",
            "Epoch 49/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5814 - loss: 1.4553 - val_accuracy: 0.3850 - val_loss: 2.3985\n",
            "Epoch 50/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5900 - loss: 1.4296 - val_accuracy: 0.4580 - val_loss: 2.3008\n",
            "Epoch 51/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6030 - loss: 1.4020 - val_accuracy: 0.4190 - val_loss: 2.3980\n",
            "Epoch 52/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6154 - loss: 1.3745 - val_accuracy: 0.4230 - val_loss: 2.4040\n",
            "Epoch 53/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6073 - loss: 1.3623 - val_accuracy: 0.4360 - val_loss: 2.3119\n",
            "Epoch 54/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5795 - loss: 1.4327 - val_accuracy: 0.4460 - val_loss: 2.3273\n",
            "Epoch 55/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6007 - loss: 1.3608 - val_accuracy: 0.4410 - val_loss: 2.4053\n",
            "Epoch 56/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6254 - loss: 1.2664 - val_accuracy: 0.4180 - val_loss: 2.3824\n",
            "Epoch 57/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6166 - loss: 1.3376 - val_accuracy: 0.4120 - val_loss: 2.4028\n",
            "Epoch 58/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.6150 - loss: 1.3032 - val_accuracy: 0.4220 - val_loss: 2.4178\n",
            "Epoch 59/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6129 - loss: 1.3147 - val_accuracy: 0.4240 - val_loss: 2.4247\n",
            "Epoch 60/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6329 - loss: 1.2642 - val_accuracy: 0.4270 - val_loss: 2.4610\n",
            "Epoch 61/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6361 - loss: 1.2571 - val_accuracy: 0.4220 - val_loss: 2.5043\n",
            "Epoch 62/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6506 - loss: 1.2263 - val_accuracy: 0.4130 - val_loss: 2.3629\n",
            "Epoch 63/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6188 - loss: 1.2979 - val_accuracy: 0.4410 - val_loss: 2.2983\n",
            "Epoch 64/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6507 - loss: 1.2365 - val_accuracy: 0.4090 - val_loss: 2.5012\n",
            "Epoch 65/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.6251 - loss: 1.2780 - val_accuracy: 0.4470 - val_loss: 2.3862\n",
            "Epoch 66/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6118 - loss: 1.3229 - val_accuracy: 0.4100 - val_loss: 2.5504\n",
            "Epoch 67/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6407 - loss: 1.2042 - val_accuracy: 0.4220 - val_loss: 2.4351\n",
            "Epoch 68/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6488 - loss: 1.1909 - val_accuracy: 0.4560 - val_loss: 2.3970\n",
            "Epoch 69/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6583 - loss: 1.1729 - val_accuracy: 0.4230 - val_loss: 2.4939\n",
            "Epoch 70/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6502 - loss: 1.2232 - val_accuracy: 0.4450 - val_loss: 2.4227\n",
            "Epoch 71/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6653 - loss: 1.1680 - val_accuracy: 0.4440 - val_loss: 2.4139\n",
            "Epoch 72/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6637 - loss: 1.1517 - val_accuracy: 0.4480 - val_loss: 2.3889\n",
            "Epoch 73/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6627 - loss: 1.1567 - val_accuracy: 0.4560 - val_loss: 2.4201\n",
            "Epoch 74/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6875 - loss: 1.0923 - val_accuracy: 0.4490 - val_loss: 2.4270\n",
            "Epoch 75/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6574 - loss: 1.1612 - val_accuracy: 0.4510 - val_loss: 2.5537\n",
            "Epoch 76/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6746 - loss: 1.1038 - val_accuracy: 0.4440 - val_loss: 2.4443\n",
            "Epoch 77/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6608 - loss: 1.1164 - val_accuracy: 0.3870 - val_loss: 2.7582\n",
            "Epoch 78/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6743 - loss: 1.1202 - val_accuracy: 0.4250 - val_loss: 2.5371\n",
            "Epoch 79/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6818 - loss: 1.0945 - val_accuracy: 0.4550 - val_loss: 2.4828\n",
            "Epoch 80/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7003 - loss: 1.0475 - val_accuracy: 0.4470 - val_loss: 2.6205\n",
            "Epoch 81/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.6934 - loss: 1.0472 - val_accuracy: 0.4350 - val_loss: 2.4819\n",
            "Epoch 82/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6940 - loss: 1.0594 - val_accuracy: 0.4390 - val_loss: 2.6406\n",
            "Epoch 83/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6654 - loss: 1.1042 - val_accuracy: 0.4430 - val_loss: 2.5687\n",
            "Epoch 84/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6996 - loss: 1.0269 - val_accuracy: 0.4290 - val_loss: 2.5901\n",
            "Epoch 85/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.6682 - loss: 1.1181 - val_accuracy: 0.4790 - val_loss: 2.4410\n",
            "Epoch 86/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6923 - loss: 1.0339 - val_accuracy: 0.4640 - val_loss: 2.5207\n",
            "Epoch 87/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6989 - loss: 0.9952 - val_accuracy: 0.4710 - val_loss: 2.5111\n",
            "Epoch 88/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.7267 - loss: 0.9672 - val_accuracy: 0.4280 - val_loss: 2.7270\n",
            "Epoch 89/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7048 - loss: 1.0053 - val_accuracy: 0.4580 - val_loss: 2.5156\n",
            "Epoch 90/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6752 - loss: 1.0414 - val_accuracy: 0.4660 - val_loss: 2.5668\n",
            "Epoch 91/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7206 - loss: 0.9508 - val_accuracy: 0.4120 - val_loss: 2.7274\n",
            "Epoch 92/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7179 - loss: 0.9616 - val_accuracy: 0.4370 - val_loss: 2.6526\n",
            "Epoch 93/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7250 - loss: 0.9368 - val_accuracy: 0.4410 - val_loss: 2.6220\n",
            "Epoch 94/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6837 - loss: 1.0679 - val_accuracy: 0.4330 - val_loss: 2.7522\n",
            "Epoch 95/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7096 - loss: 0.9671 - val_accuracy: 0.4540 - val_loss: 2.6449\n",
            "Epoch 96/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7181 - loss: 0.9722 - val_accuracy: 0.4840 - val_loss: 2.5522\n",
            "Epoch 97/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7191 - loss: 0.9227 - val_accuracy: 0.4370 - val_loss: 2.7229\n",
            "Epoch 98/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7425 - loss: 0.8951 - val_accuracy: 0.4350 - val_loss: 2.6851\n",
            "Epoch 99/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.6847 - loss: 1.0462 - val_accuracy: 0.4270 - val_loss: 2.8268\n",
            "Epoch 100/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6714 - loss: 1.1394 - val_accuracy: 0.4690 - val_loss: 2.6359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSX6ZAShJMfs"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaFG9wQyJMfs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7be2bcf-4485-4568-ecf6-b4a1351985d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    Pada bagian ini, lakukan evaluasi terhadap data training dan data testing\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "'''\n",
        "    Pada bagian ini, lakukan evaluasi terhadap data training dan data testing\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi Model\n",
        "# Prediksi pada data uji\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)  # Konversi probabilitas ke label\n",
        "\n",
        "# Hasil evaluasi menggunakan classification report\n",
        "report = classification_report(test_labels, y_pred_labels, target_names=[f'Class {i}' for i in range(LABELS_LIMIT)])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBwty2N_ZbsB",
        "outputId": "2d5830dd-cf8c-4fba-a3af-10a7adc5cac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.20      0.35      0.25        20\n",
            "     Class 1       0.48      0.50      0.49        20\n",
            "     Class 2       0.80      0.40      0.53        20\n",
            "     Class 3       0.29      0.70      0.41        20\n",
            "     Class 4       0.50      0.70      0.58        20\n",
            "     Class 5       0.54      0.35      0.42        20\n",
            "     Class 6       0.55      0.55      0.55        20\n",
            "     Class 7       0.46      0.60      0.52        20\n",
            "     Class 8       0.33      0.45      0.38        20\n",
            "     Class 9       0.29      0.30      0.29        20\n",
            "    Class 10       0.30      0.35      0.33        20\n",
            "    Class 11       0.93      0.70      0.80        20\n",
            "    Class 12       0.37      0.55      0.44        20\n",
            "    Class 13       0.42      0.50      0.45        20\n",
            "    Class 14       0.39      0.45      0.42        20\n",
            "    Class 15       0.73      0.55      0.63        20\n",
            "    Class 16       0.45      0.50      0.48        20\n",
            "    Class 17       0.31      0.25      0.28        20\n",
            "    Class 18       0.85      0.55      0.67        20\n",
            "    Class 19       0.50      0.35      0.41        20\n",
            "    Class 20       0.50      0.70      0.58        20\n",
            "    Class 21       0.31      0.20      0.24        20\n",
            "    Class 22       0.47      0.35      0.40        20\n",
            "    Class 23       0.67      0.80      0.73        20\n",
            "    Class 24       0.67      0.50      0.57        20\n",
            "    Class 25       0.47      0.40      0.43        20\n",
            "    Class 26       0.57      0.20      0.30        20\n",
            "    Class 27       0.55      0.60      0.57        20\n",
            "    Class 28       0.41      0.60      0.49        20\n",
            "    Class 29       0.31      0.45      0.37        20\n",
            "    Class 30       0.67      0.40      0.50        20\n",
            "    Class 31       0.86      0.60      0.71        20\n",
            "    Class 32       0.25      0.25      0.25        20\n",
            "    Class 33       0.80      0.60      0.69        20\n",
            "    Class 34       0.75      0.45      0.56        20\n",
            "    Class 35       0.69      0.45      0.55        20\n",
            "    Class 36       0.45      0.45      0.45        20\n",
            "    Class 37       0.36      0.50      0.42        20\n",
            "    Class 38       0.41      0.55      0.47        20\n",
            "    Class 39       0.58      0.55      0.56        20\n",
            "    Class 40       0.73      0.55      0.63        20\n",
            "    Class 41       0.29      0.20      0.24        20\n",
            "    Class 42       0.68      0.75      0.71        20\n",
            "    Class 43       0.39      0.35      0.37        20\n",
            "    Class 44       0.39      0.35      0.37        20\n",
            "    Class 45       0.43      0.30      0.35        20\n",
            "    Class 46       0.53      0.45      0.49        20\n",
            "    Class 47       0.28      0.35      0.31        20\n",
            "    Class 48       0.67      0.60      0.63        20\n",
            "    Class 49       0.38      0.30      0.33        20\n",
            "\n",
            "    accuracy                           0.47      1000\n",
            "   macro avg       0.50      0.47      0.47      1000\n",
            "weighted avg       0.50      0.47      0.47      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Model ANN dengan fitur HOG Grayscale dan PCA"
      ],
      "metadata": {
        "id": "fjdW8GjlsSKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features Extraction"
      ],
      "metadata": {
        "id": "dUBqpUsvskmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fungsi untuk melakukan ekstraksi fitur HOG\n",
        "def extract_hog_features(images):\n",
        "    hog_features = []\n",
        "    for img in images:\n",
        "        # Konversi gambar ke grayscale\n",
        "        gray_img = rgb2gray(img)\n",
        "        # Ekstraksi fitur HOG\n",
        "        features = hog(gray_img, pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                       block_norm='L2-Hys', visualize=False, feature_vector=True)\n",
        "        hog_features.append(features)\n",
        "    return np.array(hog_features)\n",
        "\n",
        "# Ekstraksi fitur HOG dari data latih dan uji\n",
        "train_hog_features = extract_hog_features(train_images)\n",
        "test_hog_features = extract_hog_features(test_images)\n",
        "\n",
        "# Standarisasi fitur sebelum PCA\n",
        "scaler = StandardScaler()\n",
        "train_hog_features = scaler.fit_transform(train_hog_features)\n",
        "test_hog_features = scaler.transform(test_hog_features)\n",
        "\n",
        "# Terapkan PCA untuk mengurangi dimensi fitur HOG\n",
        "pca = PCA(n_components=200)  # Atur jumlah komponen sesuai kebutuhan\n",
        "train_pca_features = pca.fit_transform(train_hog_features)\n",
        "test_pca_features = pca.transform(test_hog_features)\n",
        "\n",
        "print(\"Train PCA Features Shape:\", train_pca_features.shape)\n",
        "print(\"Test PCA Features Shape:\", test_pca_features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3seisibnsXZ5",
        "outputId": "80975676-baf9-4f14-a1ee-63238ee1351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PCA Features Shape: (4000, 200)\n",
            "Test PCA Features Shape: (1000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "CdeVzCIFLBbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung jumlah komponen PCA untuk dimensi input\n",
        "input_dim = train_pca_features.shape[1]\n",
        "\n",
        "print(input_dim)\n",
        "\n",
        "# Bangun model ANN yang sesuai dengan input PCA\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(input_dim,)))  # Sesuaikan input dengan dimensi hasil PCA\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(LABELS_LIMIT, activation='softmax'))\n",
        "\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Melatih model dengan data PCA\n",
        "history = model.fit(\n",
        "    train_pca_features,           # Fitur latih PCA\n",
        "    train_labels,                 # Label latih\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint_callback],  # Callback untuk penyimpanan model terbaik\n",
        "    validation_data=(test_pca_features, test_labels)\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDARWpM2uCGT",
        "outputId": "e8731c3c-e91e-4d3b-b21a-9bd38f824d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "Epoch 1/20\n",
            "\u001b[1m120/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0813 - loss: 4.0547\n",
            "Epoch 1: val_accuracy improved from -inf to 0.31800, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.0850 - loss: 4.0317 - val_accuracy: 0.3180 - val_loss: 2.8018\n",
            "Epoch 2/20\n",
            "\u001b[1m117/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5295 - loss: 1.9657\n",
            "Epoch 2: val_accuracy improved from 0.31800 to 0.50700, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5310 - loss: 1.9552 - val_accuracy: 0.5070 - val_loss: 2.0320\n",
            "Epoch 3/20\n",
            "\u001b[1m111/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.9805\n",
            "Epoch 3: val_accuracy improved from 0.50700 to 0.55900, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 0.9784 - val_accuracy: 0.5590 - val_loss: 1.8286\n",
            "Epoch 4/20\n",
            "\u001b[1m119/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.5161\n",
            "Epoch 4: val_accuracy improved from 0.55900 to 0.57300, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.5165 - val_accuracy: 0.5730 - val_loss: 1.8090\n",
            "Epoch 5/20\n",
            "\u001b[1m120/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.2681\n",
            "Epoch 5: val_accuracy improved from 0.57300 to 0.57600, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.2680 - val_accuracy: 0.5760 - val_loss: 1.8392\n",
            "Epoch 6/20\n",
            "\u001b[1m122/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.1203\n",
            "Epoch 6: val_accuracy did not improve from 0.57600\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.1204 - val_accuracy: 0.5760 - val_loss: 1.8763\n",
            "Epoch 7/20\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0632\n",
            "Epoch 7: val_accuracy improved from 0.57600 to 0.59000, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0632 - val_accuracy: 0.5900 - val_loss: 1.9074\n",
            "Epoch 8/20\n",
            "\u001b[1m113/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0373\n",
            "Epoch 8: val_accuracy improved from 0.59000 to 0.59300, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0372 - val_accuracy: 0.5930 - val_loss: 1.9541\n",
            "Epoch 9/20\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0245\n",
            "Epoch 9: val_accuracy improved from 0.59300 to 0.59500, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0246 - val_accuracy: 0.5950 - val_loss: 1.9819\n",
            "Epoch 10/20\n",
            "\u001b[1m108/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0183\n",
            "Epoch 10: val_accuracy improved from 0.59500 to 0.59900, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.5990 - val_loss: 2.0099\n",
            "Epoch 11/20\n",
            "\u001b[1m113/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0140\n",
            "Epoch 11: val_accuracy did not improve from 0.59900\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.5980 - val_loss: 2.0347\n",
            "Epoch 12/20\n",
            "\u001b[1m111/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0114\n",
            "Epoch 12: val_accuracy did not improve from 0.59900\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.5960 - val_loss: 2.0654\n",
            "Epoch 13/20\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0092\n",
            "Epoch 13: val_accuracy improved from 0.59900 to 0.60100, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.6010 - val_loss: 2.0917\n",
            "Epoch 14/20\n",
            "\u001b[1m122/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0078\n",
            "Epoch 14: val_accuracy improved from 0.60100 to 0.60200, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.6020 - val_loss: 2.1119\n",
            "Epoch 15/20\n",
            "\u001b[1m105/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066\n",
            "Epoch 15: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.6010 - val_loss: 2.1392\n",
            "Epoch 16/20\n",
            "\u001b[1m117/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0057\n",
            "Epoch 16: val_accuracy did not improve from 0.60200\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.6020 - val_loss: 2.1574\n",
            "Epoch 17/20\n",
            "\u001b[1m119/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0048\n",
            "Epoch 17: val_accuracy improved from 0.60200 to 0.60600, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.6060 - val_loss: 2.1789\n",
            "Epoch 18/20\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0041\n",
            "Epoch 18: val_accuracy did not improve from 0.60600\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.6040 - val_loss: 2.2005\n",
            "Epoch 19/20\n",
            "\u001b[1m121/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 19: val_accuracy did not improve from 0.60600\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.6030 - val_loss: 2.2214\n",
            "Epoch 20/20\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0032\n",
            "Epoch 20: val_accuracy improved from 0.60600 to 0.60700, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.6070 - val_loss: 2.2409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi"
      ],
      "metadata": {
        "id": "lDUjD7tVLFl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi pada data uji\n",
        "y_pred = model.predict(test_pca_features)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)  # Konversi probabilitas ke label\n",
        "\n",
        "# Hasil evaluasi menggunakan classification report\n",
        "report = classification_report(test_labels, y_pred_labels, target_names=[f'Class {i}' for i in range(LABELS_LIMIT)])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLDZuJLG2Mj6",
        "outputId": "b5e7ac30-63b1-4e2f-f292-6db1c9d2ddea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.39      0.45      0.42        20\n",
            "     Class 1       0.70      0.70      0.70        20\n",
            "     Class 2       0.67      0.70      0.68        20\n",
            "     Class 3       0.48      0.50      0.49        20\n",
            "     Class 4       0.54      0.70      0.61        20\n",
            "     Class 5       0.68      0.75      0.71        20\n",
            "     Class 6       0.73      0.55      0.63        20\n",
            "     Class 7       0.57      0.65      0.60        20\n",
            "     Class 8       0.50      0.60      0.55        20\n",
            "     Class 9       0.45      0.50      0.48        20\n",
            "    Class 10       0.41      0.55      0.47        20\n",
            "    Class 11       0.86      0.95      0.90        20\n",
            "    Class 12       0.72      0.65      0.68        20\n",
            "    Class 13       0.55      0.60      0.57        20\n",
            "    Class 14       0.46      0.30      0.36        20\n",
            "    Class 15       0.60      0.75      0.67        20\n",
            "    Class 16       0.61      0.70      0.65        20\n",
            "    Class 17       0.56      0.50      0.53        20\n",
            "    Class 18       0.65      0.65      0.65        20\n",
            "    Class 19       0.78      0.35      0.48        20\n",
            "    Class 20       0.74      0.70      0.72        20\n",
            "    Class 21       0.45      0.45      0.45        20\n",
            "    Class 22       0.65      0.75      0.70        20\n",
            "    Class 23       0.80      0.80      0.80        20\n",
            "    Class 24       0.67      0.50      0.57        20\n",
            "    Class 25       0.56      0.50      0.53        20\n",
            "    Class 26       0.52      0.55      0.54        20\n",
            "    Class 27       0.82      0.70      0.76        20\n",
            "    Class 28       0.64      0.80      0.71        20\n",
            "    Class 29       0.53      0.45      0.49        20\n",
            "    Class 30       0.75      0.75      0.75        20\n",
            "    Class 31       0.72      0.65      0.68        20\n",
            "    Class 32       0.67      0.60      0.63        20\n",
            "    Class 33       0.72      0.90      0.80        20\n",
            "    Class 34       0.57      0.80      0.67        20\n",
            "    Class 35       0.71      0.75      0.73        20\n",
            "    Class 36       0.55      0.55      0.55        20\n",
            "    Class 37       0.47      0.40      0.43        20\n",
            "    Class 38       0.71      0.50      0.59        20\n",
            "    Class 39       0.68      0.65      0.67        20\n",
            "    Class 40       0.76      0.80      0.78        20\n",
            "    Class 41       0.62      0.50      0.56        20\n",
            "    Class 42       0.76      0.80      0.78        20\n",
            "    Class 43       0.71      0.50      0.59        20\n",
            "    Class 44       0.41      0.45      0.43        20\n",
            "    Class 45       0.56      0.45      0.50        20\n",
            "    Class 46       0.79      0.55      0.65        20\n",
            "    Class 47       0.50      0.45      0.47        20\n",
            "    Class 48       0.53      0.45      0.49        20\n",
            "    Class 49       0.34      0.55      0.42        20\n",
            "\n",
            "    accuracy                           0.61      1000\n",
            "   macro avg       0.62      0.61      0.61      1000\n",
            "weighted avg       0.62      0.61      0.61      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menggunakan Model ANN dengan fitur HOG RGB dan PCA"
      ],
      "metadata": {
        "id": "TCHkjsk6LgPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features Extraction"
      ],
      "metadata": {
        "id": "SgH84fQ0Lvsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk melakukan ekstraksi fitur HOG pada RGB\n",
        "def extract_hog_features_rgb(images):\n",
        "    hog_features = []\n",
        "    for img in images:\n",
        "        # Ekstraksi HOG untuk setiap channel warna (R, G, dan B)\n",
        "        hog_r = hog(img[:, :, 0], pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                    block_norm='L2-Hys', visualize=False, feature_vector=True)\n",
        "        hog_g = hog(img[:, :, 1], pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                    block_norm='L2-Hys', visualize=False, feature_vector=True)\n",
        "        hog_b = hog(img[:, :, 2], pixels_per_cell=(8, 8), cells_per_block=(2, 2),\n",
        "                    block_norm='L2-Hys', visualize=False, feature_vector=True)\n",
        "\n",
        "        # Gabungkan fitur HOG dari ketiga channel\n",
        "        features = np.hstack((hog_r, hog_g, hog_b))\n",
        "        hog_features.append(features)\n",
        "\n",
        "    return np.array(hog_features)\n",
        "\n",
        "# Ekstraksi fitur HOG RGB dari data latih dan uji\n",
        "train_hog_features_rgb = extract_hog_features_rgb(train_images)\n",
        "test_hog_features_rgb = extract_hog_features_rgb(test_images)\n",
        "\n",
        "# Standarisasi fitur sebelum PCA\n",
        "train_hog_features_rgb = scaler.fit_transform(train_hog_features_rgb)\n",
        "test_hog_features_rgb = scaler.transform(test_hog_features_rgb)\n",
        "\n",
        "# Terapkan PCA untuk mengurangi dimensi fitur HOG\n",
        "pca_rgb = PCA(n_components=400)  # Atur jumlah komponen sesuai kebutuhan\n",
        "train_pca_features_rgb = pca_rgb.fit_transform(train_hog_features_rgb)\n",
        "test_pca_features_rgb = pca_rgb.transform(test_hog_features_rgb)\n",
        "\n",
        "print(\"Train PCA Features Shape:\", train_pca_features_rgb.shape)\n",
        "print(\"Test PCA Features Shape:\", test_pca_features_rgb.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WohiWOC1_Xwg",
        "outputId": "9e0de4e7-5b34-41bf-ee88-11013590e6c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train PCA Features Shape: (4000, 400)\n",
            "Test PCA Features Shape: (1000, 400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model"
      ],
      "metadata": {
        "id": "mafjiBu7L1ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hitung jumlah komponen PCA untuk dimensi input\n",
        "input_dim = train_pca_features_rgb.shape[1]\n",
        "\n",
        "print(input_dim)\n",
        "\n",
        "# Bangun model ANN yang sesuai dengan input PCA\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(input_dim,)))  # Sesuaikan input dengan dimensi hasil PCA\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(LABELS_LIMIT, activation='softmax'))\n",
        "\n",
        "# Kompilasi model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Melatih model dengan data PCA\n",
        "history = model.fit(\n",
        "    train_pca_features_rgb,           # Fitur latih PCA\n",
        "    train_labels,                 # Label latih\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    callbacks=[checkpoint_callback],  # Callback untuk penyimpanan model terbaik\n",
        "    validation_data=(test_pca_features_rgb, test_labels)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0g8Ra7LAA4l",
        "outputId": "b036e3dd-0eb7-4168-ad11-c1d04b791868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400\n",
            "Epoch 1/10\n",
            "\u001b[1m122/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1546 - loss: 4.0357\n",
            "Epoch 1: val_accuracy did not improve from 0.60700\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.1589 - loss: 4.0063 - val_accuracy: 0.4740 - val_loss: 2.0804\n",
            "Epoch 2/10\n",
            "\u001b[1m118/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8305 - loss: 0.7529\n",
            "Epoch 2: val_accuracy did not improve from 0.60700\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.7520 - val_accuracy: 0.5560 - val_loss: 1.7629\n",
            "Epoch 3/10\n",
            "\u001b[1m117/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.1382\n",
            "Epoch 3: val_accuracy did not improve from 0.60700\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.1369 - val_accuracy: 0.6010 - val_loss: 1.6925\n",
            "Epoch 4/10\n",
            "\u001b[1m118/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0241\n",
            "Epoch 4: val_accuracy improved from 0.60700 to 0.61800, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.6180 - val_loss: 1.6653\n",
            "Epoch 5/10\n",
            "\u001b[1m121/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0105\n",
            "Epoch 5: val_accuracy improved from 0.61800 to 0.62000, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0104 - val_accuracy: 0.6200 - val_loss: 1.6828\n",
            "Epoch 6/10\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0071\n",
            "Epoch 6: val_accuracy improved from 0.62000 to 0.62400, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.6240 - val_loss: 1.6910\n",
            "Epoch 7/10\n",
            "\u001b[1m120/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0052\n",
            "Epoch 7: val_accuracy improved from 0.62400 to 0.62800, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.6280 - val_loss: 1.6974\n",
            "Epoch 8/10\n",
            "\u001b[1m121/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0042\n",
            "Epoch 8: val_accuracy improved from 0.62800 to 0.62900, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.6290 - val_loss: 1.7086\n",
            "Epoch 9/10\n",
            "\u001b[1m124/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0034\n",
            "Epoch 9: val_accuracy improved from 0.62900 to 0.63000, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.6300 - val_loss: 1.7162\n",
            "Epoch 10/10\n",
            "\u001b[1m123/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 10: val_accuracy improved from 0.63000 to 0.63400, saving model to model_checkpoint_best.keras\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.6340 - val_loss: 1.7223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi"
      ],
      "metadata": {
        "id": "rsWtf2CsL4Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi pada data uji\n",
        "y_pred = model.predict(test_pca_features_rgb)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)  # Konversi probabilitas ke label\n",
        "\n",
        "# Hasil evaluasi menggunakan classification report\n",
        "report = classification_report(test_labels, y_pred_labels, target_names=[f'Class {i}' for i in range(LABELS_LIMIT)])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkBeyXdNB5YW",
        "outputId": "f637fe1b-d8e0-44a9-8b27-0549276a066e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.45      0.65      0.53        20\n",
            "     Class 1       0.67      0.70      0.68        20\n",
            "     Class 2       0.72      0.65      0.68        20\n",
            "     Class 3       0.65      0.65      0.65        20\n",
            "     Class 4       0.62      0.75      0.68        20\n",
            "     Class 5       0.82      0.70      0.76        20\n",
            "     Class 6       0.67      0.50      0.57        20\n",
            "     Class 7       0.75      0.75      0.75        20\n",
            "     Class 8       0.72      0.65      0.68        20\n",
            "     Class 9       0.55      0.60      0.57        20\n",
            "    Class 10       0.38      0.40      0.39        20\n",
            "    Class 11       0.94      0.85      0.89        20\n",
            "    Class 12       0.67      0.70      0.68        20\n",
            "    Class 13       0.65      0.75      0.70        20\n",
            "    Class 14       0.58      0.55      0.56        20\n",
            "    Class 15       0.76      0.80      0.78        20\n",
            "    Class 16       0.46      0.60      0.52        20\n",
            "    Class 17       0.45      0.50      0.48        20\n",
            "    Class 18       0.62      0.75      0.68        20\n",
            "    Class 19       0.78      0.70      0.74        20\n",
            "    Class 20       0.68      0.65      0.67        20\n",
            "    Class 21       0.35      0.40      0.37        20\n",
            "    Class 22       0.71      0.60      0.65        20\n",
            "    Class 23       0.79      0.75      0.77        20\n",
            "    Class 24       0.67      0.60      0.63        20\n",
            "    Class 25       0.50      0.70      0.58        20\n",
            "    Class 26       0.71      0.60      0.65        20\n",
            "    Class 27       0.88      0.70      0.78        20\n",
            "    Class 28       0.65      0.75      0.70        20\n",
            "    Class 29       0.59      0.50      0.54        20\n",
            "    Class 30       0.81      0.65      0.72        20\n",
            "    Class 31       0.79      0.75      0.77        20\n",
            "    Class 32       0.92      0.55      0.69        20\n",
            "    Class 33       0.74      0.70      0.72        20\n",
            "    Class 34       0.65      0.65      0.65        20\n",
            "    Class 35       0.80      0.80      0.80        20\n",
            "    Class 36       0.54      0.70      0.61        20\n",
            "    Class 37       0.55      0.60      0.57        20\n",
            "    Class 38       0.52      0.65      0.58        20\n",
            "    Class 39       0.76      0.65      0.70        20\n",
            "    Class 40       0.78      0.70      0.74        20\n",
            "    Class 41       0.80      0.40      0.53        20\n",
            "    Class 42       0.90      0.90      0.90        20\n",
            "    Class 43       0.64      0.45      0.53        20\n",
            "    Class 44       0.39      0.45      0.42        20\n",
            "    Class 45       0.36      0.50      0.42        20\n",
            "    Class 46       0.65      0.55      0.59        20\n",
            "    Class 47       0.46      0.55      0.50        20\n",
            "    Class 48       0.60      0.45      0.51        20\n",
            "    Class 49       0.57      0.60      0.59        20\n",
            "\n",
            "    accuracy                           0.63      1000\n",
            "   macro avg       0.65      0.63      0.64      1000\n",
            "weighted avg       0.65      0.63      0.64      1000\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}